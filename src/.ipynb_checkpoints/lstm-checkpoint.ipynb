{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5e56b679ec135",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T08:23:43.996239Z",
     "start_time": "2025-05-11T08:23:42.496504Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'base (Python 3.12.7)'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31m필요한 패키지를 사용하여 <a href='command:jupyter.createPythonEnvAndSelectController'>Python 환경 만들기</a>\n",
      "\u001b[1;31m또는 다음 명령을 사용하여 'ipykernel'을(를) 설치합니다. 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('C:/Users/82104/Desktop/홍콩공모전/pure-lstm/preprocess/Building_X_2nd_with_temperature.csv')\n",
    "\n",
    "# 타임스탬프를 datetime 객체로 변환\n",
    "df['record_timestamp'] = pd.to_datetime(df['record_timestamp'], dayfirst=True)\n",
    "df = df.set_index('record_timestamp')\n",
    "\n",
    "# 결측치 처리\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174eb7b43c7015c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T08:23:45.269721Z",
     "start_time": "2025-05-11T08:23:45.260533Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d039bfca29673",
   "metadata": {},
   "source": [
    "## 2. 특성 선택 및 시계열 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e5efa061bab6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T08:23:46.964732Z",
     "start_time": "2025-05-11T08:23:46.950931Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 타겟 변수 선택 (모든 냉각기의 전력 소비량 합계)\n",
    "df['total_power'] = df['CHR-01-KW'] + df['CHR-02-KW'] + df['CHR-03-KW']\n",
    "\n",
    "# 입력 특성 선택\n",
    "features = ['CHR-01-KW', 'CHR-01-CHWSWT', 'CHR-01-CHWRWT', 'CHR-01-CHWFWR',\n",
    "            'CHR-02-KW', 'CHR-02-CHWSWT', 'CHR-02-CHWRWT', 'CHR-02-CHWFWR',\n",
    "            'CHR-03-KW', 'CHR-03-CHWSWT', 'CHR-03-CHWRWT', 'CHR-03-CHWFWR',\n",
    "            'mean_temperature']\n",
    "\n",
    "# 시간 관련 특성 추가\n",
    "df['hour'] = df.index.hour\n",
    "df['day_of_week'] = df.index.dayofweek\n",
    "df['month'] = df.index.month\n",
    "\n",
    "features += ['hour', 'day_of_week', 'month']\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X = scaler_X.fit_transform(df[features])\n",
    "y = scaler_y.fit_transform(df[['total_power']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e58b38aa351d071",
   "metadata": {},
   "source": [
    "## 3. PyTorch 데이터셋 및 데이터로더 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e07a3e1c53f329",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T08:24:02.268775Z",
     "start_time": "2025-05-11T08:24:02.260863Z"
    }
   },
   "outputs": [],
   "source": [
    "class ChillerDataset(Dataset):\n",
    "    def __init__(self, X, y, seq_length=24):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 시퀀스 생성\n",
    "        X_seq = self.X[idx:idx + self.seq_length]\n",
    "        y_target = self.y[idx + self.seq_length]\n",
    "\n",
    "        # NumPy 배열을 PyTorch 텐서로 변환\n",
    "        X_seq_tensor = torch.tensor(X_seq, dtype=torch.float32)\n",
    "        y_target_tensor = torch.tensor(y_target, dtype=torch.float32)\n",
    "\n",
    "        return X_seq_tensor, y_target_tensor\n",
    "\n",
    "# 시퀀스 길이 정의 (24시간)\n",
    "seq_length = 24\n",
    "\n",
    "# 데이터셋을 시간 순서로 훈련/검증/테스트 분할 (70%, 15%, 15%)\n",
    "train_size = int(len(X) * 0.7)\n",
    "val_size = int(len(X) * 0.15)\n",
    "\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]\n",
    "X_test, y_test = X[train_size+val_size:], y[train_size+val_size:]\n",
    "\n",
    "# Dataset 객체 생성\n",
    "train_dataset = ChillerDataset(X_train, y_train, seq_length)\n",
    "val_dataset = ChillerDataset(X_val, y_val, seq_length)\n",
    "test_dataset = ChillerDataset(X_test, y_test, seq_length)\n",
    "\n",
    "# DataLoader 생성\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52ec64fd585f2a3",
   "metadata": {},
   "source": [
    "## 4. LSTM 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb401dca05f0664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T08:24:02.729434Z",
     "start_time": "2025-05-11T08:24:02.712038Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM 레이어\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout_prob if num_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "        # 드롭아웃 레이어\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "        # 최종 출력 레이어\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 초기 은닉 및 셀 상태 초기화\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # LSTM 레이어 통과\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # 마지막 시간 단계의 출력만 사용\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # 드롭아웃 적용\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # 출력 레이어 통과\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# 모델 초기화\n",
    "input_size = len(features)  # 입력 특성 개수\n",
    "hidden_size = 64  # LSTM 은닉 차원\n",
    "num_layers = 2    # LSTM 층 수\n",
    "output_size = 1   # 출력 차원 (전력 소비량)\n",
    "dropout_prob = 0.4  # 드롭아웃 확률\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size, dropout_prob)\n",
    "\n",
    "# GPU 사용 가능하면 GPU로 이동\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dbbc26f8d3496d",
   "metadata": {},
   "source": [
    "## 5. 손실 함수 및 옵티마이저 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50bd548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 손실 함수 정의\n",
    "class NormalizedRMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NormalizedRMSELoss, self).__init__()\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        # a_min과 a_max 계산 (실제값의 최소/최대)\n",
    "        a_min = torch.min(targets)\n",
    "        a_max = torch.max(targets)\n",
    "        \n",
    "        # 분모가 0이 되는 것을 방지\n",
    "        if a_max == a_min:\n",
    "            a_max = a_max + 1e-6\n",
    "        \n",
    "        # 제곱 오차 계산\n",
    "        squared_errors = (predictions - targets) ** 2\n",
    "        \n",
    "        # 평균 제곱 오차 계산\n",
    "        mse = torch.mean(squared_errors)\n",
    "        \n",
    "        # 루트 씌우기\n",
    "        rmse = torch.sqrt(mse)\n",
    "        \n",
    "        # 정규화 (a_max - a_min으로 나누기)\n",
    "        normalized_rmse = rmse / (a_max - a_min)\n",
    "        \n",
    "        return normalized_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015fb46c2f30438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T08:24:42.384629Z",
     "start_time": "2025-05-11T08:24:42.377034Z"
    }
   },
   "outputs": [],
   "source": [
    "# 손실 함수 및 옵티마이저 정의\n",
    "criterion = NormalizedRMSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습률 스케줄러 (선택 사항)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4fd924a4b716a4",
   "metadata": {},
   "source": [
    "## 6. 훈련 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7167a5e37a77a6b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T08:27:57.057180Z",
     "start_time": "2025-05-11T08:24:48.174905Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, scheduler, num_epochs, device):\n",
    "    # 커스텀 손실 함수 초기화\n",
    "    criterion = NormalizedRMSELoss()\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # 훈련 모드\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            # 데이터를 디바이스로 이동\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # 그래디언트 초기화\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 순전파\n",
    "            outputs = model(X_batch)\n",
    "\n",
    "            # 손실 계산 (커스텀 손실 함수 사용)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            # 역전파 및 옵티마이저 단계\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        # 평균 훈련 손실 계산\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # 검증 모드\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                # 데이터를 디바이스로 이동\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "                # 예측\n",
    "                outputs = model(X_batch)\n",
    "\n",
    "                # 손실 계산 (커스텀 손실 함수 사용)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        # 평균 검증 손실 계산\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # 학습률 스케줄러 업데이트\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # 최적 모델 저장\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    # 최적 모델 상태로 복원\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "# 모델 훈련\n",
    "num_epochs = 100\n",
    "model, train_losses, val_losses = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs,\n",
    "    device\n",
    ")\n",
    "\n",
    "# 훈련 진행 상황 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('모델 훈련 과정')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (Normalized RMSE)')  # 손실 함수 이름 변경\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0fb686e439f",
   "metadata": {},
   "source": [
    "## 7. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6297e3b4b32c48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T08:28:24.162859Z",
     "start_time": "2025-05-11T08:28:23.827197Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, scaler_y):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    criterion = NormalizedRMSELoss()\n",
    "\n",
    "    # 예측과 실제 값을 저장할 리스트\n",
    "    predictions = []\n",
    "    actual_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            # 데이터를 디바이스로 이동\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # 예측\n",
    "            outputs = model(X_batch)\n",
    "\n",
    "            # 손실 계산\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            test_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "            # 텐서를 CPU로 이동 후 NumPy 배열로 변환\n",
    "            predictions.append(outputs.cpu().numpy())\n",
    "            actual_values.append(y_batch.cpu().numpy())\n",
    "\n",
    "    # 평균 테스트 손실 계산\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "    # 예측값과 실제값을 하나의 배열로 병합\n",
    "    predictions = np.vstack(predictions)\n",
    "    actual_values = np.vstack(actual_values)\n",
    "\n",
    "    # 역정규화\n",
    "    predictions_denorm = scaler_y.inverse_transform(predictions)\n",
    "    actual_values_denorm = scaler_y.inverse_transform(actual_values)\n",
    "\n",
    "    # RMSE 계산\n",
    "    rmse = np.sqrt(np.mean((predictions_denorm - actual_values_denorm) ** 2))\n",
    "\n",
    "    # MAE 계산\n",
    "    mae = np.mean(np.abs(predictions_denorm - actual_values_denorm))\n",
    "\n",
    "    print(f'Test Loss (NRMSE): {test_loss:.4f}')\n",
    "    print(f'Test RMSE: {rmse:.4f}')\n",
    "    print(f'Test MAE: {mae:.4f}')\n",
    "\n",
    "    return predictions_denorm, actual_values_denorm\n",
    "\n",
    "# 모델 평가\n",
    "y_pred, y_true = evaluate_model(model, test_loader, device, scaler_y)\n",
    "\n",
    "# 예측 결과 시각화\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(y_true[:100, 0], label='value', color='blue')\n",
    "plt.plot(y_pred[:100, 0], label='prediction', color='red', linestyle='--')\n",
    "plt.title('Cooling Power Consumption Prediction Results (Partial Test Data)')\n",
    "plt.xlabel('time step')\n",
    "plt.ylabel('power consumption (kW)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c35f68c576d62",
   "metadata": {},
   "source": [
    "## 9. 모델 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded0e1e626da054e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T08:34:01.059803Z",
     "start_time": "2025-05-11T08:34:01.035999Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "def save_model(model, path, scaler_X, scaler_y):\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_config': {\n",
    "            'input_size': model.lstm.input_size,\n",
    "            'hidden_size': model.hidden_size,\n",
    "            'num_layers': model.num_layers,\n",
    "            'output_size': model.fc.out_features,\n",
    "            'dropout_prob': model.dropout.p\n",
    "        }\n",
    "    }, path)\n",
    "\n",
    "    # 스케일러 저장\n",
    "    import joblib\n",
    "    joblib.dump(scaler_X, 'scaler_X_second_add_temperature.pkl')\n",
    "    joblib.dump(scaler_y, 'scaler_y_second_add_temperature.pkl')\n",
    "\n",
    "# 모델 로드\n",
    "def load_model(path, device):\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    config = checkpoint['model_config']\n",
    "\n",
    "    model = LSTMModel(\n",
    "        input_size=config['input_size'],\n",
    "        hidden_size=config['hidden_size'],\n",
    "        num_layers=config['num_layers'],\n",
    "        output_size=config['output_size'],\n",
    "        dropout_prob=config['dropout_prob']\n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # 스케일러 로드\n",
    "    import joblib\n",
    "    scaler_X = joblib.load('scaler_X_second_add_temperature.pkl')\n",
    "    scaler_y = joblib.load('scaler_y_second_add_temperature.pkl')\n",
    "\n",
    "    return model, scaler_X, scaler_y\n",
    "\n",
    "# 모델 저장\n",
    "save_model(model, 'chiller_lstm_model_second_add_temperature.pth', scaler_X, scaler_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c4d44dbebc32c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
