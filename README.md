## 데이터 전처리 전략

- 결측치 처리: 결측치가 포함된 행을 완전히 제거 
    
    데이터의 품질을 확보하기 위한 것으로, 불완전한 정보로 인한 예측 오류를 방지함.

- 시간 데이터 변환: 문자열 형태의 타임스탬프를 datetime 객체로 변환 

    '일/월/년'을 올바르게 처리하기 위해 dayfirst=True 옵션을 사용함.

- 시간 특성 추출: 원본 타임스탬프에서 시간(hour), 요일(day_of_week), 월(month), 일(day) 등의 특성을 추출 

    전력 소비의 일일, 주간, 계절적 패턴을 포착하기 위함

- 특성 스케일링: 모든 입력 특성을 MinMaxScaler를 사용하여 [0, 1] 범위로 정규화 

    서로 다른 단위와 범위를 가진 특성들이 모델 학습에 균등하게 기여하도록 함.

- 시퀀스 데이터 생성: LSTM 모델 학습을 위해 24시간 길이의 시퀀스를 생성

    이전 24시간의 데이터를 기반으로 다음 시간의 전력 소비량을 예측하는 방식을 적용함.

- 데이터 분할: 전체 데이터셋을 시간 순서를 유지하면서 훈련(70%), 검증(15%), 테스트(15%) 세트로 분할

    랜덤 샘플링 대신 시간 순서를 보존하여 현실적인 예측 시나리오를 모방함.

## 모델 학습 전략

### LSTM 아키텍처

다층 LSTM 모델을 사용

- 2개의 LSTM 층을 사용하여 복잡한 시계열 패턴을 포착
- 64개의 은닉 유닛을 첫 번째 층에, 32개의 은닉 유닛을 두 번째 층에 배치
- 과적합 방지를 위해 20%의 드롭아웃 비율을 적용
- 최종 출력층은 단일 값(전력 소비량)을 예측하는 완전 연결 층


### 손실 함수

- 평균 제곱 오차(MSE)를 손실 함수로 사용

### 옵티마이저

- Adam 옵티마이저를 학습률 0.001로 사용

- Adaptive 학습률 적용

### 학습률 스케줄링

- ReduceLROnPlateau 스케줄러를 사용

- Validate loss가 개선되지 않을 때 학습률을 자동으로 감소시킴

    - 5번의 에폭 동안 검증 손실이 개선되지 않으면 학습률을 50% 감소

### 조기 종료

- 과적합을 방지하기 위해 검증 손실이 10번의 에폭 동안 개선되지 않으면 학습을 조기에 중단

### 배치 처리

- 배치 크기 32 사용

### 모델 저장

- 검증 손실이 가장 낮은 모델을 저장하고, 최종 평가 및 예측에 이 모델을 사용함

## 시간 기반 예측 방식

훈련된 모델은 시간 데이터만으로 전력 소비량을 예측할 수 있으므로 이를 위해 아래의 방법을 적용함.

- 시간 특성(시간, 요일, 월, 일)을 추출
- 모든 센서 관련 특성은 0으로 채움
- 입력 데이터를 정규화하고 모델에 입력
- 모델의 출력을 역정규화하여 예측된 전력 소비량을 얻음

## 모델 평가

1. 저장된 모델과 스케일러를 로드
2. 예측할 시간 데이터를 준비
3. 시간 특성을 추출하고 모델 입력 형식에 맞게 처리
4. 모델을 통해 예측을 수행
5. 결과를 재출 형식으로 저장

## 개선 가능성

- 외부 요인 통합: 날씨 데이터, 공휴일 정보 등 외부 요인을 모델에 통합하면 예측 정확도를 향상
- 앙상블 기법: 여러 모델의 예측을 결합